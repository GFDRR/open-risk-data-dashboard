# -*- coding: utf-8 -*-
# Generated by Django 1.11.1 on 2017-08-11 11:50
from __future__ import unicode_literals

import csv
import json
import codecs
from django.db import migrations
import django.conf as conf
import os
import subprocess
from collections import namedtuple

KeyDataset_in = namedtuple('KeyDataset_in', 'category id hazard_category'
                           ' dataset tag description comment format resolution'
                           ' RiverFlooding CoastalFlooding Tsunami Cyclone'
                           ' Earthquake Volcano Landslide WaterScarcity'
                           ' international national local weight')


def forwards_func(apps, schema_editor):
    db_alias = schema_editor.connection.alias

    Country = apps.get_model("ordd_api", "Country")
    Region = apps.get_model("ordd_api", "Region")
    KeyCategory = apps.get_model("ordd_api", "KeyCategory")
    KeyTag = apps.get_model("ordd_api", "KeyTag")
    KeyTagGroup = apps.get_model("ordd_api", "KeyTagGroup")

    KeyDatasetName = apps.get_model("ordd_api", "KeyDatasetName")
    KeyLevel = apps.get_model("ordd_api", "KeyLevel")
    KeyDataset = apps.get_model("ordd_api", "KeyDataset")

    database_name = conf.settings.DATABASES['default']['NAME']
    print("\n%s DBNAME [%s]\n" % (
        __file__, database_name))
    name = os.path.join(os.path.dirname(__file__), '..',
                        'helpers', 'load_content_script.py')
    print("DBNAME: %s" % database_name)
    os.environ.update({'ORDD_OVERRIDE_DBNAME': database_name})

    sub = subprocess.run(['python3', name])
    if sub.returncode != 0:
        raise ValueError('load_content_script.py return [%d]'
                         % sub.returncode)

    # call_command('load_countries', '--filein',
    #              'contents/countries/ordd_countries_list_iso3166.csv',
    #              verbosity=0, interactive=False)

    filein = os.path.join('contents', 'countries',
                          'ordd_countries_list_iso3166.csv')

    with codecs.open(filein, 'rb', encoding='utf-8') as csvfile:
        countries = csv.reader(csvfile, delimiter=',')

        region_cur = None
        for country_in in countries:
            if country_in[1]:
                region_cur = Region.objects.using(db_alias).create(
                    name=country_in[1])
            Country.objects.using(db_alias).create(
                iso2=country_in[0], name=country_in[2], region=region_cur)

    # call_command('load_key_datasets', '--reload', '--filein',
    #              'contents/key_datasets/kd-categories.csv',
    #              'contents/key_datasets/kd-tags.csv',
    #              'contents/key_datasets/kd-datasets.csv',
    #              verbosity=0, interactive=False)

    kd_categories_filein = os.path.join('contents', 'key_datasets',
                                        'kd-categories.csv')
    kd_tags_filein = os.path.join('contents', 'key_datasets',
                                  'kd-tags.csv')
    kd_datasets_filein = os.path.join('contents', 'key_datasets',
                                      'kd-datasets.csv')

    # load categories
    with (codecs.open(
            kd_categories_filein, 'rb', encoding='utf-8')) as csvfile:
        KeyCategory.objects.using(db_alias).all().delete()

        categories = csv.reader(csvfile)
        for category_in in categories:
            KeyCategory.objects.using(db_alias).create(
                code=category_in[0], name=category_in[1],
                weight=category_in[2])

    # load tags
    with (codecs.open(kd_tags_filein, 'rb', encoding='utf-8')) as csvfile:
        KeyTag.objects.using(db_alias).all().delete()
        KeyTagGroup.objects.using(db_alias).all().delete()

        tags = csv.reader(csvfile)
        for tag_in in tags:
            tag_group = KeyTagGroup.objects.using(db_alias).get_or_create(
                name=tag_in[0])
            tag_group = tag_group[0]
            if tag_in[0] == 'hazard':
                is_peril = True
            else:
                is_peril = False
            tag = KeyTag.objects.using(db_alias).create(
                group=tag_group, name=tag_in[1], is_peril=is_peril)

    kd_row = -1
    with (codecs.open(kd_datasets_filein, 'rb',
          encoding='utf-8')) as csvfile:
        keydatasets = csv.reader(csvfile)

        KeyDatasetName.objects.using(db_alias).all().delete()
        KeyLevel.objects.using(db_alias).all().delete()
        KeyDataset.objects.using(db_alias).all().delete()

        KeyLevel.objects.using(db_alias).create(
            name='International')
        KeyLevel.objects.using(db_alias).create(
            name='National')
        KeyLevel.objects.using(db_alias).create(
            name='Local')

        # prev_cat = None
        # cat_cur = None

        for kd_row, kd_in in enumerate(keydatasets):

            # Sanitize all the trailing and leading spaces
            for n, kd_in_clean in enumerate(kd_in):
                kd_in[n] = kd_in_clean.strip()

            if kd_in[0] == '' or kd_in[0] == 'NN':
                continue

            composite_id = kd_in[0].split('_')
            composite_ds = kd_in[1].split(' - ')

            if len(composite_ds) == 2:
                hazard_category = composite_ds[0]
                dataset = composite_ds[1]
            elif len(composite_ds) == 1:
                hazard_category = None
                dataset = composite_ds[0]
            else:
                raise ValueError('Too many \'-\' separators in'
                                 ' dataset \'%s\'' % kd_in[1])

            keyobj_in = KeyDataset_in(
                category=KeyCategory.objects.using(db_alias).get(
                    code=composite_id[0]),
                id=kd_in[0], hazard_category=hazard_category,
                dataset=dataset, tag=kd_in[2], description=kd_in[3],
                comment=kd_in[4], format=kd_in[5], resolution=kd_in[6],
                RiverFlooding=kd_in[7], CoastalFlooding=kd_in[8],
                Tsunami=kd_in[9], Cyclone=kd_in[10],
                Earthquake=kd_in[11], Volcano=kd_in[12],
                Landslide=kd_in[13], WaterScarcity=kd_in[14],
                international=kd_in[15], national=kd_in[16],
                local=kd_in[17], weight=kd_in[18])

            # Category
            category = KeyCategory.objects.using(db_alias).filter(
                                            name=keyobj_in.category.name)
            if len(category) != 1:
                raise ValueError('Category: [%s] not exists in list'
                                 % keyobj_in.category.name)
            category = category[0]

            # DatasetName
            dataset = KeyDatasetName.objects.using(db_alias).get_or_create(
                                    name=keyobj_in.dataset,
                                    category=keyobj_in.hazard_category)
            dataset = dataset[0]

            # TagGroup
            if keyobj_in.tag == '':
                tag = None
            else:
                tag = KeyTagGroup.objects.using(db_alias).filter(
                                        name__iexact=keyobj_in.tag)
                if len(tag) != 1:
                    raise ValueError('Tag group: [%s] not exists'
                                     ' in list' % keyobj_in.tag)
                tag = tag[0]

            names = {'international': 'International',
                     'national': 'National',
                     'local': 'Local'}
            ct = 0
            for sca_field in ['international', 'national', 'local']:
                cur_value = getattr(keyobj_in, sca_field, None)
                if cur_value is not None:
                    cur_value = cur_value.strip()
                    if cur_value == '':
                        continue
                else:
                    continue

                level = KeyLevel.objects.using(db_alias).filter(
                    name=names[sca_field])
                ct += 1

            if ct != 1:
                keydata_level = KeyLevel.objects.using(db_alias).get(
                    name='National')
                print('Keydataset from row %d isn\'t assinged'
                      ' to any applicability level:'
                      ' \'National\' will be used then.'
                      % (kd_row), Warning)
            else:
                keydata_level = level[0]

            keydata = KeyDataset.objects.using(db_alias).create(
                code=keyobj_in.id, category=category, dataset=dataset,
                description=keyobj_in.description, tag_available=tag,
                resolution=keyobj_in.resolution,
                format=keyobj_in.format,
                comment=keyobj_in.comment, weight=keyobj_in.weight,
                level=keydata_level)

            for app in ['River flooding', 'Coastal flooding',
                        'Tsunami', 'Cyclone', 'Earthquake',
                        'Volcano', 'Landslide', 'Water scarcity']:
                cur_value = getattr(keyobj_in,
                                    app.title().replace(' ', ''),
                                    None)
                if cur_value is not None:
                    cur_value = cur_value.strip()
                    if cur_value == '':
                        continue
                else:
                    continue

                peril = KeyTag.objects.using(db_alias).filter(
                    name=app, group__name="hazard")
                if len(peril) != 1:
                    raise ValueError('Tag: [%s] does not match single'
                                     ' peril item' % app)

                keydata.applicability.add(peril[0])

    #    call_command('load_thinkhazard', '--datapath',
    #                 './contents/thinkhazard/cache',
    #                 verbosity=0, interactive=False)
    datapath = os.path.join('contents', 'thinkhazard', 'cache')

    peril_mapping = {
        "FL": "River flooding",
        "UF": None,
        "CF": "Coastal flooding",
        "EQ": "Earthquake",
        "LS": "Landslide",
        "TS": "Tsunami",
        "VA": "Volcano",
        "CY": "Cyclone",
        "DG":  "Water scarcity",
        "EH": None,
        "WF": None
        }

    level_mapping = {
        "HIG": True,
        "MED": True,
        "LOW": False,
        "VLO": False,
        "no-data": False,
        }

    country_mapping = {
        "Iran": "Iran  (Islamic Republic of)",
        "the Republic of Korea": "Dem People's Rep of Korea",
        "Czechia": "Czech Republic",
        "Macedonia": "The former Yugoslav Republic of Macedonia",
        "Moldova": "Moldova, Republic of",

        # does is it the right approssimation ?
        "United Kingdom of Great Britain and Northern Ireland":
            "United Kingdom",
        "Cabo Verde": "Cape Verde",
        "the Democratic Republic of the Congo":
            "Democratic Republic of the Congo",
        "the Congo": "Congo",

        # does is it the right approssimation ?
        "Saint Helena, Ascension and Tristan da Cunha": "Saint Helena",
        "Tanzania": "United Republic of Tanzania",
        "Western Sahara*": "Western Sahara",
    }

    th_data = []

    peril_instances = KeyTag.objects.using(db_alias).filter(
        group__name='hazard').order_by('name')
    peril = {}
    for peril_instance in peril_instances:
        peril[peril_instance.name] = peril_instance

    for filename in os.listdir(datapath):
        if (filename.startswith("adm_division_") and
                filename.endswith(".json")):
            with codecs.open(
                    os.path.join(datapath, filename),
                    'rb', encoding='utf-8') as json_file:
                th_data += json.load(json_file)['data']

    found = 0
    not_found = 0
    for country in Country.objects.using(db_alias).all().order_by('id'):
        country.thinkhazard_appl.clear()

        if country.name in country_mapping:
            country_name = country_mapping[country.name]
        else:
            country_name = country.name

        report_cou_name = country.name.replace('*', '_STAR_')

        for th in th_data:
            if 'admin0' not in th:
                continue
            if th['admin0'] == country_name:
                if 'admin1' in th:
                    # print("FOUND BUT WITH admin1, continue")
                    continue
                print("Found: %d) %s: %s" % (
                    country.id, country_name, th['code']))
                found += 1

                report_filename = os.path.join(
                    datapath, 'reports',
                    'report_%s.json' % report_cou_name)

                # here data loading
                with open(report_filename, 'r',
                          encoding='utf-8') as report_file:
                    decoded_data = report_file.read()

                appls = json.loads(decoded_data)

                with open(report_filename, 'w',
                          encoding='utf-8') as report_file:
                    report_file.write(decoded_data)

                for appl in appls:
                    th_peril = appl['hazardtype']['mnemonic']
                    peril_name = peril_mapping[th_peril]
                    if peril_name is None:
                        continue
                    th_level = appl['hazardlevel']['mnemonic']
                    level = level_mapping[th_level]
                    if not level:
                        continue
                    country.thinkhazard_appl.add(peril[peril_name])
                break
        else:
            print("%d) %s NOT FOUND" % (country.id, country_name))
            not_found += 1

    print("Report: found %d, Not found %d" % (found, not_found))


def backwards_func(apps, schema_editor):
    pass


class Migration(migrations.Migration):

    dependencies = [
        ('ordd_api', '0012_optin_insert_time'),
    ]

    operations = [
        migrations.RunPython(forwards_func, backwards_func),
    ]
